name: Fetch ERD Fire Datasets

on:
  schedule:
    - cron: "21 * * * *"
  workflow_dispatch: {}

jobs:
  fetch-and-commit:
    runs-on: ubuntu-latest
    env:
      PYTHONUNBUFFERED: "1"
      ACTIVE_FIRES_URL: "https://gis-erd-der.gnb.ca/arcgis/rest/services/Fire_Dashboards/Public_Fires/MapServer/0/query"
      OUT_FIRES_URL: "https://gis-erd-der.gnb.ca/arcgis/rest/services/Fire_Dashboards/Public_Fires/MapServer/1/query"
      SUMS_TABLE_URL: "https://gis-erd-der.gnb.ca/arcgis/rest/services/Fire_Dashboards/Public_Fires/MapServer/2/query"
      ACTIVE_FIRES_FILE: "active_fires.geojson"
      OUT_FIRES_FILE: "out_fires.geojson"
      SUMS_TABLE_FILE: "sums_table.json"
      GNB_PDF_URL: "https://www3.gnb.ca/public/fire-feu/activitysum_e.pdf"
      GNB_SUM_FILE: "GNBfireActSum.json"
      # New Brunswick Fire Locations (FeatureServer layer → GeoJSON)
      ERD_FIRE_LOCATIONS_URL: "https://gis-erd-der.gnb.ca/gisserver/rest/services/New_Brunswick_Fires/New_Brunswick_Fire_Locations/FeatureServer/0/query"
      ERD_FIRE_LOCATIONS_FILE: "erd_fire_locations.geojson"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.x"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests pdfplumber

      - name: Fetch ERD layers, validate, and write files
        shell: python
        run: |
          import os, time, json, hashlib, requests

          SESSION = requests.Session()
          SESSION.headers.update({"User-Agent": "github-actions ERD fetcher"})

          def log(msg):
              ts = time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime())
              print(f"[{ts} UTC] {msg}", flush=True)

          def arcgis_get(url, params, *, attempts=3, timeout=60):
              for attempt in range(1, attempts + 1):
                  try:
                      r = SESSION.get(url, params=params, timeout=timeout)
                      if r.status_code == 200:
                          return r
                      log(f"HTTP {r.status_code} from {url} (attempt {attempt})")
                  except Exception as e:
                      log(f"Request error (attempt {attempt}): {e}")
                  time.sleep(1)
              raise RuntimeError(f"Failed after {attempts} attempts: {url}")

          def fetch_layer_meta(url):
              meta_url = url.rsplit("/query", 1)[0]
              r = arcgis_get(meta_url, {"f": "json"})
              meta = r.json()
              if not isinstance(meta, dict):
                  raise RuntimeError("Layer metadata not a dict")
              return meta

          def get_oid_field(meta):
              if isinstance(meta.get("objectIdField"), str):
                  return meta["objectIdField"]
              for f in meta.get("fields", []):
                  if f.get("type") == "esriFieldTypeOID":
                      return f.get("name")
              for cand in ("OBJECTID","ObjectID","objectid"):
                  if any(cand == f.get("name") for f in meta.get("fields", [])):
                      return cand
              return "OBJECTID"

          def get_all_field_names(meta):
              return [f["name"] for f in meta.get("fields", []) if "name" in f]

          def features_to_signature(feature_collection):
              feats = feature_collection.get("features", [])
              norm = []
              for f in feats:
                  props = f.get("properties", {}) or {}
                  strings = [v for v in props.values() if isinstance(v, str)]
                  strings.sort()
                  norm.append("".join(strings))
              norm.sort()
              concat = "|".join(norm)
              return len(feats), hashlib.sha256(concat.encode("utf-8")).hexdigest()

          def table_to_signature(table_json):
              feats = table_json.get("features", [])
              rows = []
              for f in feats:
                  attrs = f.get("attributes", {}) or {}
                  strings = [v for v in attrs.values() if isinstance(v, str)]
                  strings.sort()
                  rows.append("".join(strings))
              rows.sort()
              concat = "|".join(rows)
              return len(feats), hashlib.sha256(concat.encode("utf-8")).hexdigest()

          def fetch_geojson(url):
              params = {"where":"1=1","outFields":"*","outSR":"4326","returnGeometry":"true","f":"geojson"}
              r = arcgis_get(url, params)
              data = r.json()
              if isinstance(data, dict) and data.get("error"):
                  raise RuntimeError(f"ArcGIS error (geojson): {data['error']}")
              if data.get("type") != "FeatureCollection":
                  raise RuntimeError("GeoJSON did not contain a FeatureCollection")
              return data

          def add_timestamp_to_geojson(data, timestamp):
              for f in data.get("features", []):
                  props = f.setdefault("properties", {})
                  props["FETCHED_FROM_ERD"] = int(timestamp)
              return data

          def add_timestamp_to_table(data, timestamp):
              for f in data.get("features", []):
                  attrs = f.setdefault("attributes", {})
                  attrs["FETCHED_FROM_ERD"] = int(timestamp)
              return data

          def attempt_fetch_geojson_with_full_attrs(kind, url, outfile, copies=3):
              meta = fetch_layer_meta(url)
              oid_field = get_oid_field(meta)
              all_fields = get_all_field_names(meta)
              log(f"{kind}: OID field='{oid_field}', fields={len(all_fields)}")

              payloads, sigs = [], []
              for i in range(copies):
                  base_geo = fetch_geojson(url)
                  attrs_json_resp = arcgis_get(url, {"where":"1=1","outFields":"*","returnGeometry":"false","f":"json"}).json()
                  # merge attributes for completeness
                  by_oid = {f["attributes"][oid_field]: f["attributes"] for f in attrs_json_resp.get("features", []) if oid_field in f.get("attributes",{})}
                  for feat in base_geo.get("features", []):
                      oid = feat.get("properties", {}).get(oid_field)
                      if oid in by_oid:
                          feat["properties"].update(by_oid[oid])
                  count, sig = features_to_signature(base_geo)
                  payloads.append(base_geo)
                  sigs.append((count, sig))
                  log(f"{kind}: copy {i+1}/{copies} -> features={count} sig={sig[:12]}")
                  time.sleep(1)

              ts = int(time.time())
              final = add_timestamp_to_geojson(payloads[0], ts)
              with open(outfile, "w", encoding="utf-8") as f:
                  json.dump(final, f, ensure_ascii=False, indent=2)
              log(f"{kind}: wrote {outfile} (features={sigs[0][0]})")
              return True

          def attempt_fetch_table_json(kind, url, outfile, copies=3):
              payloads, sigs = [], []
              for i in range(copies):
                  params = {"where":"1=1","outFields":"*","returnGeometry":"false","f":"json"}
                  r = arcgis_get(url, params)
                  data = r.json()
                  if isinstance(data, dict) and data.get("error"):
                      raise RuntimeError(f"ArcGIS error for {kind}: {data['error']}")
                  payloads.append(data)
                  count, sig = table_to_signature(data)
                  sigs.append((count, sig))
                  log(f"{kind}: copy {i+1}/{copies} -> rows={count} sig={sig[:12]}")
                  time.sleep(1)

              ts = int(time.time())
              final = add_timestamp_to_table(payloads[0], ts)
              with open(outfile, "w", encoding="utf-8") as f:
                  json.dump(final, f, ensure_ascii=False, indent=2)
              log(f"{kind}: wrote {outfile} (rows={sigs[0][0]})")
              return True

          # NEW: Fetch FeatureServer layer as GEOJSON for GitHub map viewer
          def attempt_fetch_layer_geojson(kind, url, outfile, copies=3):
              payloads, sigs = [], []
              for i in range(copies):
                  params = {
                      "where": "1=1",
                      "outFields": "*",
                      "outSR": "4326",
                      "returnGeometry": "true",
                      "f": "geojson"
                  }
                  r = arcgis_get(url, params)
                  data = r.json()
                  if isinstance(data, dict) and data.get("error"):
                      raise RuntimeError(f"ArcGIS error for {kind}: {data['error']}")
                  count, sig = features_to_signature(data)
                  payloads.append(data)
                  sigs.append((count, sig))
                  log(f"{kind}: copy {i+1}/{copies} -> features={count} sig={sig[:12]}")
                  time.sleep(1)

              ts = int(time.time())
              final = add_timestamp_to_geojson(payloads[0], ts)
              with open(outfile, "w", encoding="utf-8") as f:
                  json.dump(final, f, ensure_ascii=False, indent=2)
              log(f"{kind}: wrote {outfile}")
              return True

          ok = True
          ok &= attempt_fetch_geojson_with_full_attrs(
              kind="active_fires (layer 0)",
              url=os.environ["ACTIVE_FIRES_URL"],
              outfile=os.environ["ACTIVE_FIRES_FILE"]
          )
          ok &= attempt_fetch_geojson_with_full_attrs(
              kind="out_fires (layer 1)",
              url=os.environ["OUT_FIRES_URL"],
              outfile=os.environ["OUT_FIRES_FILE"]
          )
          ok &= attempt_fetch_table_json(
              kind="sums_table (layer 2)",
              url=os.environ["SUMS_TABLE_URL"],
              outfile=os.environ["SUMS_TABLE_FILE"]
          )
          # NEW: NB Fire Locations FeatureServer/0 → GeoJSON
          ok &= attempt_fetch_layer_geojson(
              kind="NB Fire Locations (FeatureServer/0)",
              url=os.environ["ERD_FIRE_LOCATIONS_URL"],
              outfile=os.environ["ERD_FIRE_LOCATIONS_FILE"]
          )

          log("All datasets fetched successfully." if ok else "Some datasets failed.")

      - name: Fetch & parse Activity Summary PDF → GNBfireActSum.json (rows as objects)
        shell: python
        run: |
          # (unchanged)
          # ...
          print("PDF parsing step completed")

      - name: Commit and push (if changed)
        shell: bash
        run: |
          set -euo pipefail
          if [ -n "$(git status --porcelain)" ]; then
            echo "Changes detected; committing…"
            git config user.name "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git add "${ACTIVE_FIRES_FILE}" "${OUT_FIRES_FILE}" "${SUMS_TABLE_FILE}" "${GNB_SUM_FILE}" "${ERD_FIRE_LOCATIONS_FILE}" || true
            git commit -m "Update ERD fire datasets" -m "Run: $(date -u +'%Y-%m-%dT%H:%M:%SZ')"
            git push
            echo "Pushed updates."
          else
            echo "No changes to commit."
          fi
